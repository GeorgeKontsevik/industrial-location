{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "with open('/home/gk/Downloads/Telegram Desktop/pair_dists_reversed_2.pkl', 'rb') as f:\n",
    "    my_dict = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.cluster import DBSCAN\n",
    "from sklearn.metrics import silhouette_score\n",
    "from tqdm import tqdm\n",
    "\n",
    "num_points = int(np.sqrt(len(my_dict) * 2))\n",
    "\n",
    "# Convert the dictionary into a distance matrix\n",
    "distance_matrix = np.zeros((num_points+20, num_points+20))\n",
    "for k, v in tqdm(my_dict.items()):\n",
    "    i, j = k\n",
    "    distance_matrix[i, j] = v\n",
    "    distance_matrix[j, i] = v\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = pd.DataFrame(distance_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.manifold import TSNE\n",
    "# import plotly.express as px\n",
    "\n",
    "tsne = TSNE(n_components=2, perplexity=100, n_iter=1000, random_state=7575)\n",
    "tsne_results = tsne.fit_transform(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.mixture import GaussianMixture as GMM\n",
    "\n",
    "\n",
    "from sklearn import metrics\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "tqdm.pandas()\n",
    "\n",
    "def SelBest(arr:list, X:int)->list:\n",
    "    '''\n",
    "    returns the set of X configurations with shorter distance\n",
    "    '''\n",
    "    dx=np.argsort(arr)[:X]\n",
    "    return arr[dx]\n",
    "\n",
    "n_clusters=np.arange(30, 60)\n",
    "# n_clusters=np.arange(10, 11)\n",
    "sils=[]\n",
    "sils_err=[]\n",
    "iterations=20\n",
    "for n in tqdm(n_clusters):\n",
    "    tmp_sil=[]\n",
    "    for _ in range(iterations):\n",
    "        gmm=GMM(n, n_init=2, random_state=7575, covariance_type='diag', init_params='kmeans').fit(tsne_results) \n",
    "        labels=gmm.predict(tsne_results)\n",
    "        sil=metrics.silhouette_score(tsne_results, labels, metric='euclidean')\n",
    "        tmp_sil.append(sil)\n",
    "    val=np.mean(SelBest(np.array(tmp_sil), int(iterations/5)))\n",
    "    err=np.std(tmp_sil)\n",
    "    sils.append(val)\n",
    "    sils_err.append(err)\n",
    "\n",
    "plt.errorbar(n_clusters, sils, yerr=sils_err)\n",
    "plt.title(\"Silhouette Scores\", fontsize=20)\n",
    "plt.xticks(n_clusters)\n",
    "plt.xlabel(\"N. of clusters\")\n",
    "plt.ylabel(\"Score\")\n",
    "\n",
    "dct_tmp = {n_clusters[i]: sils[i] for i in range(len(n_clusters))}\n",
    "max_score_clust = max(dct_tmp, key=dct_tmp.get)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eps_range = np.arange(0.1, 2.1, 0.1)\n",
    "min_samples_range = np.arange(2, 21, 1)\n",
    "best_score = -1\n",
    "best_eps = 0\n",
    "best_min_samples = 0\n",
    "for eps in tqdm(eps_range):\n",
    "    for min_samples in min_samples_range:\n",
    "        dbscan = DBSCAN(eps=eps, min_samples=min_samples)\n",
    "        labels = dbscan.fit_predict(tsne_results)\n",
    "        n_clusters = len(set(labels)) - (1 if -1 in labels else 0)\n",
    "        if 20 <= n_clusters <= 50:  # check if number of clusters is between 20 and 50\n",
    "            score = silhouette_score(tsne_results, labels)\n",
    "            if score > best_score:\n",
    "                best_score = score\n",
    "                best_eps = eps\n",
    "                best_min_samples = min_samples\n",
    "\n",
    "print(f\"Best silhouette score: {best_score:.2f}, Best eps: {best_eps:.2f}, Best min samples: {best_min_samples}\")\n",
    "\n",
    "# decrease eps for smaller leafs\n",
    "best_eps /= 2\n",
    "\n",
    "# perform bdscan clustering on t-SNE output using the optimal parameters\n",
    "dbscan = DBSCAN(eps=best_eps, min_samples=best_min_samples)\n",
    "labels = dbscan.fit_predict(tsne_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import hdbscan\n",
    "\n",
    "# find optimal parameters for hdbscan\n",
    "min_cluster_size_range = np.arange(10, 30, 1)\n",
    "best_score = -1\n",
    "best_min_cluster_size = 0\n",
    "for min_cluster_size in tqdm(min_cluster_size_range):\n",
    "    hdbscan_model = hdbscan.HDBSCAN(min_cluster_size=min_cluster_size)\n",
    "    hdbscan_labels = hdbscan_model.fit_predict(tsne_results)\n",
    "    n_clusters = len(set(hdbscan_labels)) - (1 if -1 in hdbscan_labels else 0)\n",
    "    if n_clusters >= 3:  # check if number of clusters is at least 3\n",
    "        score = silhouette_score(tsne_results, hdbscan_labels)\n",
    "        if score > best_score:\n",
    "            best_score = score\n",
    "            best_min_cluster_size = min_cluster_size\n",
    "\n",
    "print(f\"Best silhouette score: {best_score:.2f}, Best min_cluster_size: {best_min_cluster_size}\")\n",
    "\n",
    "# perform hdbscan clustering on t-SNE output using the optimal parameters\n",
    "hdbscan_model = hdbscan.HDBSCAN(min_cluster_size=best_min_cluster_size)\n",
    "hdbscan_labels = hdbscan_model.fit_predict(tsne_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import OPTICS\n",
    "\n",
    "min_samples_range = np.arange(2, 21, 1)\n",
    "best_score = -1\n",
    "best_min_samples = 0\n",
    "for min_samples in tqdm(min_samples_range):\n",
    "    optics = OPTICS(min_samples=min_samples)\n",
    "    optics.fit(tsne_results)\n",
    "    labels = optics.labels_\n",
    "    n_clusters = len(set(labels)) - (1 if -1 in labels else 0)\n",
    "    if n_clusters >= 3:  # check if number of clusters is at least 3\n",
    "        score = silhouette_score(tsne_results, labels)\n",
    "        if score > best_score:\n",
    "            best_score = score\n",
    "            best_min_samples = min_samples\n",
    "\n",
    "print(f\"Best silhouette score: {best_score:.2f}, Best min samples: {best_min_samples}\")\n",
    "\n",
    "# perform optics clustering on t-SNE output using the optimal parameters\n",
    "optics = OPTICS(min_samples=best_min_samples)\n",
    "optics.fit(tsne_results)\n",
    "labels = optics.labels_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# max_score_clust"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute the DBSCAN clustering with your custom distance matrix\n",
    "# gmm = GMM(n_components=max_score_clust, random_state=7575, covariance_type='diag', init_params='kmeans').fit_predict(tsne_results)\n",
    "\n",
    "# # Compute the silhouette score\n",
    "# labels = dbscan.labels_\n",
    "# silhouette_avg = silhouette_score(distance_matrix, labels, metric='precomputed')\n",
    "# print(\"The silhouette score is:\", silhouette_avg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "\n",
    "G = nx.read_graphml('/home/gk/code/migration_project/G12.graphml')\n",
    "\n",
    "import geopandas as gpd\n",
    "from shapely.wkt import loads\n",
    "\n",
    "# assuming you already have a graph G with node data that includes a \"geometry\" attribute\n",
    "# use the nodes method from networkx to get a NodeDataView object\n",
    "nodedata = G.nodes(data=True)\n",
    "\n",
    "# create a list of dictionaries to store the attributes of each node\n",
    "node_attrs = []\n",
    "for n, data in nodedata:\n",
    "    node_dict = data.copy()\n",
    "    node_dict[\"nodeID\"] = n\n",
    "    node_dict[\"geometry\"] = loads(node_dict[\"geometry\"])\n",
    "    node_attrs.append(node_dict)\n",
    "\n",
    "# create a GeoDataFrame from the list of node attributes, using the \"geometry\" attribute as the geometry\n",
    "nodes_gdf = gpd.GeoDataFrame(node_attrs, geometry='geometry', crs=4326)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nodes_gdf.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nodes_gdf.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nodes_gdf['cluster'] = hdbscan_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nodes_gdf.to_file('nodes_gdf_HDBSCAN_4.geojson')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
